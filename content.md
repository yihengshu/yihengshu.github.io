# Yiheng Shu

### PhD student, The Ohio State University

<section class="profile-links">
  <div class="contact-inline">
    <a class="contact-item" href="https://cse.osu.edu/" target="_blank" rel="noopener noreferrer" aria-label="The Ohio State University Department of Computer Science and Engineering" title="OSU CSE">
      <span class="icon" aria-hidden="true">
        <svg viewBox="0 0 24 24" width="18" height="18" fill="none" stroke="currentColor" stroke-width="1.8" stroke-linecap="round" stroke-linejoin="round">
          <path d="M12 22s7-5.5 7-12a7 7 0 1 0-14 0c0 6.5 7 12 7 12Z"></path>
          <circle cx="12" cy="10" r="2.6"></circle>
        </svg>
      </span>
      <span>Columbus, OH</span>
    </a>
    <a class="contact-item" href="mailto:shu.251@osu.edu" aria-label="Email shu.251@osu.edu">
      <span class="icon" aria-hidden="true">
        <svg viewBox="0 0 24 24" width="18" height="18" fill="none" stroke="currentColor" stroke-width="1.8" stroke-linecap="round" stroke-linejoin="round">
          <rect x="3.5" y="5.5" width="17" height="13" rx="2"></rect>
          <path d="M4.5 7l7.5 6 7.5-6"></path>
        </svg>
      </span>
      <span>shu.251 [at] osu.edu</span>
    </a>
    <a class="contact-item" href="https://yihengshu.github.io/files/C.V.pdf" target="_blank" rel="noopener noreferrer" aria-label="Curriculum vitae PDF" title="CV">
      <span class="icon" aria-hidden="true">
        <svg viewBox="0 0 24 24" width="18" height="18" fill="none" stroke="currentColor" stroke-width="1.8" stroke-linecap="round" stroke-linejoin="round">
          <path d="M8 3.5h6l4 4V20a1.5 1.5 0 0 1-1.5 1.5h-8A1.5 1.5 0 0 1 7 20V5A1.5 1.5 0 0 1 8.5 3.5Z"></path>
          <path d="M14 3.5V8h4"></path>
          <path d="M9.2 12.4h5.6M9.2 15.4h5.6"></path>
        </svg>
      </span>
      <span>CV</span>
    </a>
  </div>

  <div class="link-cluster">
    <a class="link-chip icon-only" href="https://github.com/yhshu" target="_blank" rel="noopener noreferrer" aria-label="GitHub profile" title="GitHub">
      <span class="icon" aria-hidden="true">
        <svg viewBox="0 0 24 24" width="18" height="18" fill="currentColor">
          <path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path>
        </svg>
      </span>
    </a>
    <a class="link-chip icon-only" href="https://huggingface.co/yhshu" target="_blank" rel="noopener noreferrer" aria-label="Hugging Face profile" title="Hugging Face">
      <span class="icon" aria-hidden="true">
        <svg viewBox="0 0 24 24" width="18" height="18" fill="currentColor">
          <path d="M12.025 1.13c-5.77 0-10.449 4.647-10.449 10.378 0 1.112.178 2.181.503 3.185.064-.222.203-.444.416-.577a.96.96 0 0 1 .524-.15c.293 0 .584.124.84.284.278.173.48.408.71.694.226.282.458.611.684.951v-.014c.017-.324.106-.622.264-.874s.403-.487.762-.543c.3-.047.596.06.787.203s.31.313.4.467c.15.257.212.468.233.542.01.026.653 1.552 1.657 2.54.616.605 1.01 1.223 1.082 1.912.055.537-.096 1.059-.38 1.572.637.121 1.294.187 1.967.187.657 0 1.298-.063 1.921-.178-.287-.517-.44-1.041-.384-1.581.07-.69.465-1.307 1.081-1.913 1.004-.987 1.647-2.513 1.657-2.539.021-.074.083-.285.233-.542.09-.154.208-.323.4-.467a1.08 1.08 0 0 1 .787-.203c.359.056.604.29.762.543s.247.55.265.874v.015c.225-.34.457-.67.683-.952.23-.286.432-.52.71-.694.257-.16.547-.284.84-.285a.97.97 0 0 1 .524.151c.228.143.373.388.43.625l.006.04a10.3 10.3 0 0 0 .534-3.273c0-5.731-4.678-10.378-10.449-10.378M8.327 6.583a1.5 1.5 0 0 1 .713.174 1.487 1.487 0 0 1 .617 2.013c-.183.343-.762-.214-1.102-.094-.38.134-.532.914-.917.71a1.487 1.487 0 0 1 .69-2.803m7.486 0a1.487 1.487 0 0 1 .689 2.803c-.385.204-.536-.576-.916-.71-.34-.12-.92.437-1.103.094a1.487 1.487 0 0 1 .617-2.013 1.5 1.5 0 0 1 .713-.174m-10.68 1.55a.96.96 0 1 1 0 1.921.96.96 0 0 1 0-1.92m13.838 0a.96.96 0 1 1 0 1.92.96.96 0 0 1 0-1.92M8.489 11.458c.588.01 1.965 1.157 3.572 1.164 1.607-.007 2.984-1.155 3.572-1.164.196-.003.305.12.305.454 0 .886-.424 2.328-1.563 3.202-.22-.756-1.396-1.366-1.63-1.32q-.011.001-.02.006l-.044.026-.01.008-.03.024q-.018.017-.035.036l-.032.04a1 1 0 0 0-.058.09l-.014.025q-.049.088-.11.19a1 1 0 0 1-.083.116 1.2 1.2 0 0 1-.173.18q-.035.029-.075.058a1.3 1.3 0 0 1-.251-.243 1 1 0 0 1-.076-.107c-.124-.193-.177-.363-.337-.444-.034-.016-.104-.008-.2.022q-.094.03-.216.087-.06.028-.125.063l-.13.074q-.067.04-.136.086a3 3 0 0 0-.135.096 3 3 0 0 0-.26.219 2 2 0 0 0-.12.121 2 2 0 0 0-.106.128l-.002.002a2 2 0 0 0-.09.132l-.001.001a1.2 1.2 0 0 0-.105.212q-.013.036-.024.073c-1.139-.875-1.563-2.317-1.563-3.203 0-.334.109-.457.305-.454m.836 10.354c.824-1.19.766-2.082-.365-3.194-1.13-1.112-1.789-2.738-1.789-2.738s-.246-.945-.806-.858-.97 1.499.202 2.362c1.173.864-.233 1.45-.685.64-.45-.812-1.683-2.896-2.322-3.295s-1.089-.175-.938.647 2.822 2.813 2.562 3.244-1.176-.506-1.176-.506-2.866-2.567-3.49-1.898.473 1.23 2.037 2.16c1.564.932 1.686 1.178 1.464 1.53s-3.675-2.511-4-1.297c-.323 1.214 3.524 1.567 3.287 2.405-.238.839-2.71-1.587-3.216-.642-.506.946 3.49 2.056 3.522 2.064 1.29.33 4.568 1.028 5.713-.624m5.349 0c-.824-1.19-.766-2.082.365-3.194 1.13-1.112 1.789-2.738 1.789-2.738s.246-.945.806-.858.97 1.499-.202 2.362c-1.173.864.233 1.45.685.64.451-.812 1.683-2.896 2.322-3.295s1.089-.175.938.647-2.822 2.813-2.562 3.244 1.176-.506 1.176-.506 2.866-2.567 3.49-1.898-.473 1.23-2.037 2.16c-1.564.932-1.686 1.178-1.464 1.53s3.675-2.511 4-1.297c.323 1.214-3.524 1.567-3.287 2.405.238.839 2.71-1.587 3.216-.642.506.946-3.49 2.056-3.522 2.064-1.29.33-4.568 1.028-5.713-.624"></path>
        </svg>
      </span>
    </a>
    <a class="link-chip icon-only" href="https://twitter.com/YihengShu" target="_blank" rel="noopener noreferrer" aria-label="Twitter profile" title="X">
      <span class="icon" aria-hidden="true">
        <svg viewBox="0 0 24 24" width="18" height="18" fill="currentColor">
          <path d="M14.234 10.162 22.977 0h-2.072l-7.591 8.824L7.251 0H.258l9.168 13.343L.258 24H2.33l8.016-9.318L16.749 24h6.993zm-2.837 3.299-.929-1.329L3.076 1.56h3.182l5.965 8.532.929 1.329 7.754 11.09h-3.182z"></path>
        </svg>
      </span>
    </a>
    <a class="link-chip icon-only" href="https://www.linkedin.com/in/shuyh" target="_blank" rel="noopener noreferrer" aria-label="LinkedIn profile" title="LinkedIn">
      <span class="icon" aria-hidden="true">
        <svg viewBox="0 0 24 24" width="18" height="18" fill="currentColor">
          <path d="M22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0zM7.114 20.452H3.558V8.999h3.556zm-1.778-13.02a2.062 2.062 0 1 1 0-4.124 2.062 2.062 0 0 1 0 4.124m15.116 13.02h-3.555v-5.57c0-1.327-.027-3.036-1.852-3.036-1.853 0-2.136 1.445-2.136 2.939v5.667H9.353V9h3.413v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.602 0 4.27 2.37 4.27 5.455z"></path>
        </svg>
      </span>
    </a>
    <a class="link-chip icon-only" href="https://scholar.google.com/citations?user=H63aXLcAAAAJ&hl=en" target="_blank" rel="noopener noreferrer" aria-label="Google Scholar profile" title="Google Scholar">
      <span class="icon" aria-hidden="true">
        <svg viewBox="0 0 24 24" width="18" height="18" fill="currentColor">
          <path d="M5.242 13.769L0 9.5 12 0l12 9.5-5.242 4.269C17.548 11.249 14.978 9.5 12 9.5c-2.977 0-5.548 1.748-6.758 4.269zM12 10a7 7 0 1 0 0 14 7 7 0 0 0 0-14z"></path>
        </svg>
      </span>
    </a>
    <a class="link-chip icon-only" href="https://www.semanticscholar.org/author/Yiheng-Shu/1406331721" target="_blank" rel="noopener noreferrer" aria-label="Semantic Scholar profile" title="Semantic Scholar">
      <span class="icon" aria-hidden="true">
        <svg viewBox="0 0 24 24" width="18" height="18" fill="currentColor">
          <path d="M24 8.609c-.848.536-1.436.83-2.146 1.245-4.152 2.509-8.15 5.295-11.247 8.981l-1.488 1.817-4.568-7.268c1.021.814 3.564 3.098 4.603 3.599l3.356-2.526c2.336-1.644 8.946-5.226 11.49-5.848ZM8.046 15.201c.346.277.692.537.969.744.761-3.668.121-7.613-1.886-11.039 3.374-.052 6.731-.087 10.105-.139a14.794 14.794 0 0 1 1.298 5.295c.294-.156.588-.294.883-.433-.104-1.868-.641-3.91-1.662-6.263-4.602-.018-9.188-.018-13.79-.018 2.993 3.547 4.36 7.839 4.083 11.853Zm-.623-.484c.087.086.191.155.277.225-.138-3.409-1.419-6.887-3.824-9.881H1.73c3.098 2.855 4.984 6.299 5.693 9.656Zm-.744-.658c.104.087.208.173.329.277-.9-2.526-2.492-5.018-4.741-7.198H0c2.89 2.076 5.122 4.481 6.679 6.921Z"></path>
        </svg>
      </span>
    </a>
    <a class="link-chip icon-only" href="https://dblp.org/pid/239/6116.html" target="_blank" rel="noopener noreferrer" aria-label="DBLP profile" title="DBLP">
      <span class="icon" aria-hidden="true">
        <svg viewBox="0 0 24 24" width="18" height="18" fill="currentColor">
          <path d="M3.075.002c-.096.013-.154.092-.094.31L4.97 7.73 3.1 8.6s-.56.26-.4.85l2.45 9.159s.16.59.72.33l6.169-2.869 1.3-.61s.52-.24.42-.79l-.01-.06-1.13-4.22-.658-2.45-.672-2.49v-.04s-.16-.59-.84-1L3.5.141s-.265-.16-.425-.139zM18.324 5.03a.724.724 0 0 0-.193.06l-5.602 2.6.862 3.2 1.09 4.08.01.06c.05.47-.411.79-.411.79l-1.88.87.5 1.89.04.1c.07.17.28.6.81.91l6.95 4.269s.68.41.52-.17l-1.981-7.4 1.861-.86s.56-.26.4-.85L18.85 5.42s-.116-.452-.526-.39z"></path>
        </svg>
      </span>
    </a>
    <a class="link-chip icon-only" href="http://orcid.org/0000-0002-7536-2503" target="_blank" rel="noopener noreferrer" aria-label="ORCID profile" title="ORCID">
      <span class="icon" aria-hidden="true">
        <svg viewBox="0 0 24 24" width="18" height="18" fill="currentColor">
          <path d="M12 0C5.372 0 0 5.372 0 12s5.372 12 12 12 12-5.372 12-12S18.628 0 12 0zM7.369 4.378c.525 0 .947.431.947.947s-.422.947-.947.947a.95.95 0 0 1-.947-.947c0-.525.422-.947.947-.947zm-.722 3.038h1.444v10.041H6.647V7.416zm3.562 0h3.9c3.712 0 5.344 2.653 5.344 5.025 0 2.578-2.016 5.025-5.325 5.025h-3.919V7.416zm1.444 1.303v7.444h2.297c3.272 0 4.022-2.484 4.022-3.722 0-2.016-1.284-3.722-4.097-3.722h-2.222z"></path>
        </svg>
      </span>
    </a>
  </div>
</section>

## About Me

I’m a doctoral student at [The Ohio State University](https://cse.osu.edu/) since 2023, advised by [Prof. Yu Su](https://ysu1989.github.io/).

My research explores retrieval-augmented generation (RAG) and memory for language agents. Specifically, I focus on: 1) developing efficient information retrieval approaches to enhance reasoning and long-term memory capabilities [[HippoRAG](https://arxiv.org/abs/2405.14831)] [[HippoRAG 2](https://arxiv.org/abs/2502.14802)] [REMem], and 2) integrating these models with complex external environments such as the Web, knowledge graphs [[TIARA](https://arxiv.org/abs/2210.12925)], and databases [[Middleware](https://arxiv.org/abs/2402.14672)].

I received my Master degree from [Nanjing University](https://www.nju.edu.cn/en/) in 2023 and Bachelor degree from [Northeastern University (China)](http://sc.neu.edu.cn/english/main.htm) in 2020. I was research intern at [Intuit](https://www.intuit.com/ai/research/) in 2025 and at [Microsoft Research Asia](https://www.msra.cn/) in 2022.

Feel free to reach out to me if you’re interested in my research.

## Publications

*: Equal Contribution

- **[ICLR'26]** REMem: Reasoning with Episodic Memory in Language Agent  
**Yiheng Shu**, Saisri Padmaja Jonnalagedda, Xiang Gao, Bernal Jiménez Gutiérrez, Weijian Qi, Kamalika Das, Huan Sun, Yu Su  
[[paper](https://openreview.net/forum?id=fugnQxbvMm&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2026%2FConference%2FAuthors%23your-submissions))] [code]

- **[NeurIPS'25]** Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge  
Boyu Gou*, Zanming Huang*, Yuting Ning*, Yu Gu, Michael Lin, Weijian Qi, Andrei Kopanev, Botao Yu, Bernal Jiménez Gutiérrez, **Yiheng Shu**, Chan Hee Song, Jiaman Wu, Shijie Chen, Hanane Nour Moussa, Tianshu Zhang, Jian Xie, Yifei Li, Tianci Xue, Zeyi Liao, Kai Zhang, Boyuan Zheng, Zhaowei Cai, Viktor Rozgic, Morteza Ziyadi, Huan Sun, Yu Su  
[[paper](https://arxiv.org/abs/2506.21506)] [[project](https://osu-nlp-group.github.io/Mind2Web-2/)] [[BibTex](https://dblp.org/rec/journals/corr/abs-2506-21506.html?view=bibtex)]

- **[ICML'25]** From RAG to Memory: Non-Parametric Continual Learning for Large Language Model  
Bernal Jiménez Gutiérrez*, **Yiheng Shu**\*, Weijian Qi, Sizhe Zhou, Yu Su  
[[paper](https://arxiv.org/abs/2502.14802)] [[code (3k stars)](https://github.com/OSU-NLP-Group/HippoRAG)] [[data](https://huggingface.co/datasets/osunlp/HippoRAG_2/tree/main)] [[poster](https://icml.cc/media/PosterPDFs/ICML%202025/45585.png?t=1752374674.436611)] [[talk](https://paperclub.aitinkerers.org/p/join-our-paper-club-with-ohio-state-from-rag-to-memory-non-parametric-continual-learning-for-large-language-models)] [[BibTex](https://dblp.org/rec/conf/icml/GutierrezSQZ025.html?view=bibtex)]

- **[ICLR'25 Oral]** Navigating the Digital World as Humans Do: Universal Visual Grounding for GUI Agents  
Boyu Gou, Ruohan Wang, Boyuan Zheng, Yanan Xie, Cheng Chang, **Yiheng Shu**, Huan Sun, Yu Su  
 [[paper](https://arxiv.org/abs/2410.05243)] [[code](https://github.com/OSU-NLP-Group/UGround)] [[home](https://osu-nlp-group.github.io/UGround/)] [[poster](https://iclr.cc/media/iclr-2025/Slides/32062.pdf)] [[BibTex](https://dblp.org/rec/conf/iclr/GouWZXCS0025.html?view=bibtex)]

- **[NeurIPS'24]** HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models  
Bernal Jiménez Gutiérrez, **Yiheng Shu**, Yu Gu, Michihiro Yasunaga, Yu Su  
[[paper](https://arxiv.org/abs/2405.14831)] [[code](https://github.com/OSU-NLP-Group/HippoRAG/tree/legacy)] [[proceedings](https://proceedings.neurips.cc/paper_files/paper/2024/hash/6ddc001d07ca4f319af96a3024f6dbd1-Abstract-Conference.html)] [[poster](https://neurips.cc/virtual/2024/poster/94043)] [[BibTex](https://proceedings.neurips.cc/paper_files/paper/25031-/bibtex)]

- **[EMNLP'24]** Middleware for LLMs: Tools Are Instrumental for Language Agents in Complex Environments  
Yu Gu, **Yiheng Shu**, Hao Yu, Xiao Liu, Yuxiao Dong, Jie Tang, Jayanth Srinivasa, Hugo Latapie, Yu Su  
[[paper](https://arxiv.org/abs/2402.14672)] [[code](https://github.com/OSU-NLP-Group/Fuxi)] [[benchmark](https://huggingface.co/datasets/osunlp/KBQA-Agent)] [[proceedings](https://aclanthology.org/2024.emnlp-main.436/)] [[BibTeX](https://aclanthology.org/2024.emnlp-main.436.bib)]

- **[EACL'24 SRW]** Distribution Shifts Are Bottlenecks: Extensive Evaluation for Grounding Language Models to Knowledge Bases  
**Yiheng Shu**, Zhiwei Yu  
[[paper](https://arxiv.org/abs/2309.08345)] [[code](https://github.com/yhshu/Distribution-Shifts-for-KBQA)] [[data](https://huggingface.co/datasets/yhshu/TIARA-GAIN/tree/main)] [[poster](https://s3.amazonaws.com/pf-user-files-01/u-59356/uploads/2024-02-11/4f13myd/EACL%202024%20SRW%20poster.pdf)] [[video](https://s3.amazonaws.com/pf-user-files-01/u-59356/uploads/2024-02-11/6103mrr/EACL%202024%20SRW%20slides.mp4)] [[proceedings](https://aclanthology.org/2024.eacl-srw.7/)] [[BibTeX](https://aclanthology.org/2024.eacl-srw.7.bib)]

- **[AAAI'23]** Question Decomposition Tree for Answering Complex Questions over Knowledge Bases  
Xiang Huang, Sitao Cheng, **Yiheng Shu**, Yuheng Bao, Yuzhong Qu  
[[paper](https://arxiv.org/abs/2306.07597)] [[code](https://github.com/cdhx/QDTQA)] [[proceedings](https://ojs.aaai.org/index.php/AAAI/article/view/26519/26291)] [[BibTeX](https://dblp.org/rec/conf/aaai/HuangCSBQ23.html?view=bibtex)]

- **[EMNLP'22]** TIARA: Multi-grained Retrieval for Robust Question Answering over Large Knowledge Base  
**Yiheng Shu**, Zhiwei Yu, Yuhan Li, Börje F. Karlsson, Tingting Ma, Yuzhong Qu, Chin-Yew Lin  
[[paper](https://arxiv.org/abs/2210.12925)] [[code](https://github.com/microsoft/KC/tree/main/papers/TIARA)] [[data](https://drive.google.com/file/d/171vTwW-tO4_5DdEzlYljj2-M3YHvegYF/view?usp=sharing)] [[poster](https://yihengshu.github.io/files/EMNLP22poster.pdf)] [[slides](https://yihengshu.github.io/files/EMNLP22slides.pdf)] [[video](https://s3.amazonaws.com/pf-user-files-01/u-59356/uploads/2022-11-04/fr03tjr/EMNLP22.mp4)] [[proceedings](https://aclanthology.org/2022.emnlp-main.555/)] [[BibTeX](https://aclanthology.org/2022.emnlp-main.555.bib)]

- **[COLING'22]** Logical Form Generation via Multi-task Learning for Complex Question Answering over Knowledge Bases  
Xixin Hu, Xuan Wu, **Yiheng Shu**, Yuzhong Qu  
[[paper](https://aclanthology.org/2022.coling-1.145.pdf)] [[code](https://github.com/HXX97/GMT-KBQA)] [[slides](https://s3.amazonaws.com/pf-user-files-01/u-59356/uploads/2022-09-23/ff53s0y/1216_GMTKBQA_presentation.pdf)] [[video](https://s3.amazonaws.com/pf-user-files-01/u-59356/uploads/2022-09-23/8y23sus/1216_GMTKBQA_video.mp4)] [[proceedings](https://aclanthology.org/2022.coling-1.145/)] [[BibTeX](https://aclanthology.org/2022.coling-1.145.bib)]

- **[ISWC'21]** EDG-based Question Decomposition for Complex Question Answering over Knowledge Bases  
Xixin Hu, **Yiheng Shu**, Xiang Huang, Yuzhong Qu  
[[paper](https://www.researchgate.net/profile/Xixin-Hu/publication/354925951_EDG-Based_Question_Decomposition_for_Complex_Question_Answering_over_Knowledge_Bases/links/63023efae3c7de4c3472860d/EDG-Based-Question-Decomposition-for-Complex-Question-Answering-over-Knowledge-Bases.pdf)] [[code](http://github.com/HXX97/EDGQA)] [[home](http://edgqa.github.io)] [[video](http://videolectures.net/iswc2021_1a_question_decomposition/)] [[proceedings](https://link.springer.com/chapter/10.1007/978-3-030-88361-4_8)] [[BibTeX](https://dblp.org/rec/conf/semweb/HuSHQ21.html?view=bibtex)]

- **[TOIS'20]** Deep Learning for Sequential Recommendation: Algorithms, Influential Factors, and Evaluations  
Hui Fang, Danning Zhang, **Yiheng Shu**, Guibing Guo  
[[paper](https://arxiv.org/abs/1905.01997)] [[code](https://github.com/sttich/dl-recommendation)] [[ACM Library](https://dl.acm.org/doi/10.1145/3426723)] [[BibTeX](https://dblp.org/rec/journals/tois/FangZSG20.html?view=bibtex)]

- **[ICWE'19 tutorial]** Deep Learning-based Sequential Recommender Systems: Concepts, Algorithms, and Evaluations  
Hui Fang, Danning Zhang, Guibing Guo, **Yiheng Shu**  
[[slides](http://web.geni-pco.com/icwe2019/tutorial2_DL-based_rs.pdf)] [[intro](https://icwe2019.webengineering.org/program_tutorials/)] [[Springer Link](https://link.springer.com/chapter/10.1007/978-3-030-19274-7_47)] [[BibTeX](https://dblp.org/rec/conf/icwe/0002GZS19.html?view=bibtex)]

<details>
<summary><strong>Services</strong></summary>

- Program committee: [AAAI’26](https://aaai.org/conference/aaai/aaai-26/)
- Conference reviewer: [ICLR'26](https://iclr.cc/Conferences/2026), [NeurIPS’25](https://neurips.cc/), [ARR’25](https://aclrollingreview.org/) (ACL’25, EMNLP’25), [ARR’24](https://aclrollingreview.org/) (ACL’24, EMNLP’24, NAACL’24)
- Workshop reviewer: [WiNLP’24](https://www.winlp.org/winlp-2024-workshop/), [ICLR’25 Reasoning and Planning for LLMs](https://workshop-llm-reasoning-planning.github.io/)
- Journal reviewer: [IEEE Trans. Big Data](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6687317)

</details>

<details>
<summary><strong>Awards and Honors</strong></summary>

- Excellent Graduates, Nanjing University, 2023
- Excellent Postgraduate Student, Nanjing University, 2022
- First-class Yingcai Scholarship, Nanjing University, 2022
- First-class Academic Scholarship for Master Students, Nanjing University, 2020-2022
- Provincial Excellent Graduates, Education Department of Liaoning Province, 2020
- Meritorious Winner of The Mathematical Contest in Modeling, COMAP, 2019
- Suzhou Industrial Park Scholarship, Northeastern University, 2019
- National Scholarship, Ministry of Education of the P.R. China, 2018
- Pacemaker to Excellent Students, Northeastern University, 2018
- Excellent Student, Northeastern University, 2017

</details>

<!-- ## Resources

I serve as a member of MLNLP, a large AI community in China. Our recent works include:

- [MLNLP 2023 Annual Symposium](http://mlnlp.world/mlnlp2023/) for 24 academic talks about foundation models (>21k participants)
- [MLNLP 2022 Annual Symposium](http://www.mlnlp2022.com) (>36k participants)
- [MLNLP/Paper-Writing-Tips](https://github.com/MLNLP-World/Paper_Writing_Tips) (>3k GitHub stars) for researchers and students
- [MLNLP/WeChat-Group](https://github.com/MLNLP-World/Top-Conference-WeChat-Group) for top-tier AI conference
- [MLNLP/NLP-Course-Chinese](https://github.com/MLNLP-World/NLP-Course-Chinese) for translated NLP Blogs
- [MLNLP/AI-Paper-Collector](https://github.com/MLNLP-World/AI-Paper-Collector) for collecting AI-related papers -->

Last update: Feb 7, 2026
